name,ring,quadrant,isNew,description,,,,,,,,,,,,,,,,,,,,,OIDC for GitHub Actions,Assess,Techniques,TRUE,"<p>One of the techniques we recommend for implementing <a href=""/radar/techniques/zero-trust-security-for-ci-cd"">zero trust security for CI/CD</a> is to authenticate your pipelines for cloud services access via federated identity mechanisms like OpenID Connect (OIDC). As <a href=""/radar/platforms/github-actions"">GitHub Actions</a> is widely used — and this important technique remains underused — we want to call out <strong><a href=""https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect"">OIDC for GitHub Actions</a></strong>. This way you can avoid storing long-lived access tokens for your cloud resources, and your pipelines won't get direct access to secrets. However, be sure to scope access carefully <a href=""https://securitylabs.datadoghq.com/articles/exploring-github-to-aws-keyless-authentication-flaws/"">so that actions really run with least privilege</a>.</p>",,,,,,,,,,,,,,,,,,,,,Zero trust security for CI/CD,Assess,Techniques,FALSE,"<p>If not properly secured, the infrastructure and tools that run our build and delivery pipelines can become a big liability. Pipelines need access to critical data and systems like source code, credentials and secrets to build and deploy software. This makes these systems very inviting to malicious actors. We therefore highly recommend applying <strong><a href=""/radar/techniques/zero-trust-architecture"">zero trust</a> security for CI/CD</strong> pipelines and infrastructure — trusting them as little as necessary. This encompasses a number of techniques: If available, authenticate your pipelines with your cloud provider via federated identity mechanisms like <a href=""/radar/techniques/oidc-for-github-actions"">OIDC</a>, instead of giving them direct access to secrets; implement the principle of least privilege by minimizing the access of individual user or runner accounts, rather than employing ""god user accounts"" with unlimited access; use your runners in an ephemeral way instead of reusing them, to reduce the risk of exposing secrets from previous jobs or running jobs on compromised runners; keep the software in your agents and runners up to date; and monitor the integrity, confidentiality and availability of your CI/CD systems the same way you would monitor your production software.</p>

<p>We're seeing teams forget about these types of practices, particularly when they’re used to working with a self-managed CI/CD infrastructure in internal network zones. While all of these practices are important in your internal networks, they become even more crucial when using a managed service, as that extends the attack surface and blast radius even more.</p>",,,,,,,,,,,,,,,,,,,,,GitOps,Assess,Techniques,FALSE,"<p><strong>GitOps</strong> is a technique for deploying applications via the <a href=""https://kubernetes.io/docs/concepts/architecture/controller/"">control loop</a> pattern. An operator keeps the deployed application synchronized with configuration, usually a Git repository. When we last wrote about GitOps, the community had yet to agree on a definition of the term. At the time, we were concerned about common interpretations of the technique that included approaches like ""branch per environment"" for configuration, which may lead to <a href=""https://infrastructure-as-code.com/book/2021/11/19/snowflakes-as-code.html"">snowflakes as code</a>. Moreover, the messaging around GitOps as an alternative to continuous delivery was confusing. Since then, the four <a href=""https://github.com/open-gitops/documents/blob/main/PRINCIPLES.md"">GitOps principles</a> have clarified the scope and nature of the technique. When you peel away the hype and confusion, GitOps is a useful technique that takes advantage of the functionality of a <a href=""/radar/platforms/kubernetes"">Kubernetes</a> cluster and creates opportunities to separate concerns between configuring an application and the implementation of the deployment process. Some of our teams have implemented GitOps as part of their continuous delivery setup with positive experiences, which is why we recommend assessing it.</p>",,,,,,,,,,,,,,,,,,,,,Azure Container Apps,Assess,Platforms,TRUE,"<p><strong><a href=""https://azure.microsoft.com/en-us/products/container-apps"">Azure Container Apps</a></strong> is a managed <a href=""/radar/platforms/kubernetes"">Kubernetes</a> namespace as a service that streamlines the deployment of containerized workloads by eliminating the need for intricate maintenance of Kubernetes clusters and underlying infrastructure components, consequently diminishing operational and administrative burdens. However, it’s essential to tread carefully while considering this option; currently in its developmental phase, it has exhibited inconsistencies in the Azure portal's representation of its capabilities and encounters integration hurdles, particularly with the standard Terraform provider for Azure lagging in mirroring the tool's actual functionalities. Given all this, we recommend assessing this tool carefully.</p>",,,,,,,,,,,,,,,,,,,,,Azure OpenAI Service,Assess,Platforms,TRUE,"<p>With the huge interest in generative AI, many solutions have sprung up to access the major models. If considering or already using Azure, then it's worth assessing <strong><a href=""https://azure.microsoft.com/en-us/products/ai-services/openai-service/"">Azure OpenAI Service</a></strong>. It provides access to OpenAI's GPT-4, GPT-35-Turbo and Embeddings models through a REST API, a Python SDK and a web-based interface. The models can be adapted to tasks such as content generation, summarization, semantic search and natural language to code translation. Fine-tuning is also available via few-shot learning and the customization of hyperparameters. In comparison to OpenAI's own API, Azure OpenAI Service benefits from Azure's enterprise-grade security and compliance features; it's also available in more regions, although <a href=""https://azure.microsoft.com/en-us/explore/global-infrastructure/products-by-region/?regions=all&products=cognitive-services"">availability is limited</a> for each of the larger geographic regions, and, as of writing, India is not included.</p>",,,,,,,,,,,,,,,,,,,,,ChatGLM,Assess,Platforms,TRUE,"<p>There are many emerging large language models (LLMs) in the English-speaking world. Although these models are usually pretrained with multiple languages, their performance in other languages may not be as good as in English. <strong><a href=""https://github.com/THUDM/ChatGLM2-6B"">ChatGLM</a></strong>, developed by Tsinghua University, is an open bilingual language model optimized for Chinese conversation based on the <a href=""https://arxiv.org/abs/2103.10360"">General Language Model</a> architecture. Since Chinese can be more complex than English with its different word segmentation and grammar, it’s important to have an LLM optimized for Chinese. Our team found ChatGLM beat other LLMs in accuracy and robustness when we built a Chinese emotion detection application for a call center. Considering many LLMs aren’t available in China due to licensing or regional restrictions, ChatGLM became one of the few open-source options.</p>",,,,,,,,,,,,,,,,,,,,,GitHub Copilot,Trial,Tools,FALSE,"<p><strong><a href=""https://github.com/features/copilot"">GitHub Copilot</a></strong> is used by many of our teams to help them write code faster. Overall, most of our developers find it very useful and would be cross if we took it away from them. We've been collating and sharing many of our experiences with Copilot through <a href=""https://martinfowler.com/articles/exploring-gen-ai.html"">a series on Generative AI</a> and <a href=""https://www.thoughtworks.com/insights/blog/generative-ai/getting-started-with-github-copilot"">a guide on getting started with Copilot</a>. Note that GitHub Copilot can be used with any codebase, not just codebases hosted on GitHub.</p>

<p>We're also excited that Copilot's chat feature from the <a href=""https://github.com/features/preview/copilot-x"">Copilot X roadmap</a> has become more widely available since we last featured it in the Radar. It is a powerful addition to Copilot's in-line assistance feature. The availability of a chat interface inside the IDE improves the discoverability of commonly searched information, and integration with the open editor context makes it easy to explore errors or ask the chat to assist with tasks related to the code in focus.</p>",,,,,,,,,,,,,,,,,,,,,ChatGPT,Assess,Tools,FALSE,"<p><strong><a href=""https://openai.com/blog/chatgpt"">ChatGPT</a></strong> continues to attract attention. Imaginative use cases and innovative approaches to prompting mean it's gaining expanding utility over time. GPT4, the large language model (LLM) that powers ChatGPT, now also has the ability to integrate with external tools such as a knowledge management repository, sandboxed coding environment or web search. The recent introduction of <a href=""https://openai.com/blog/introducing-chatgpt-enterprise"">ChatGPT Enterprise</a> may help ease intellectual property concerns, while providing ""enterprise"" features such as usage tracking and better user management through SSO.</p>

<p>Although ChatGPT's ability to ""write"" code has been much vaunted, we think organizations should be looking at using it across the full software lifecycle to improve efficiency and reduce errors. For example, ChatGPT can provide additional perspectives or suggestions for tasks as diverse as requirements analysis, architectural design or the reverse engineering of legacy systems. We still think ChatGPT is best used as an input to a process — such as helping with a first draft of a story or the boilerplate for a coding task — rather than a tool that produces ""fully baked"" results. That said, its capabilities are improving each week, and some programming tasks may now be fully possible by careful prompting, which is an <a href=""/radar/techniques/prompt-engineering"">art in itself</a>.</p>",,,,,,,,,,,,,,,,,,,,,Codeium,Assess,Tools,TRUE,"<p>In the AI-powered coding assistants space, <strong><a href=""https://codeium.com/"">Codeium</a></strong> is one of the more promising products. Similar to <a href=""/radar/tools/tabnine"">Tabnine</a>, Codeium tries to address some of the biggest concerns companies have about coding assistants: They reduce at least some of the open-source licensing concerns, because they do not train their models with code from repositories with nonpermissive licenses. They also offer self-hosting for the tool so you don't have to send your code snippets to a third-party service. Codeium stands out for its broad support of IDEs and notebook services, and although it hasn't been around for as long as <a href=""/radar/tools/github-copilot"">GitHub Copilot</a> or Tabnine, our first impressions of the product have been positive.</p>",,,,,,,,,,,,,,,,,,,,,GitHub merge queue,Assess,Tools,TRUE,"<p>We've long been advocates of short-lived developer branches that are merged frequently into the main code branch, which is kept ready for deployment. This practice of trunk-based development goes hand-in-hand with continuous integration and, when conditions permit, results in the fastest feedback cycles and most efficient developer flow. However, not everyone favors this approach, and we frequently adapt our style to accommodate our clients’ practices. Sometimes this includes long-lived feature branches followed by pull requests that must be manually reviewed and approved before they're merged into the main branch. In these situations, we use the TRUE <strong><a href=""https://github.blog/2023-07-12-github-merge-queue-is-generally-available/"">GitHub merge queue</a></strong> feature. It allows us to automatically queue up incoming pull requests and merge them into a special branch in the order they were received. We then have the option of automating our own ""merge checks"" to prevent incompatible commits. This essentially simulates trunk-based development (even though PRs have not been merged into the main code branch yet) and allows developers to test their features in context without having to wait for the pull request to be approved. With GitHub merge queue, you get the benefits of trunk-based development even when you're not able to fully commit to it.</p>",,,,,,,,,,,,,,,,,,,,,Google Bard,Assess,Tools,TRUE,"<p><strong><a href=""https://bard.google.com/"">Google Bard</a></strong> is a generative AI chatbot developed by Google AI. Much like <a href=""/radar/tools/chatgpt"">ChatGPT</a>, it’s conversational and able to communicate and generate human-like text in response to a wide range of prompts and questions. Bard is powered by Google's <a href=""https://ai.google/discover/palm2/"">Pathways Language Model (PaLM 2)</a>, which is a large language model (LLM) that’s trained on a massive data set of text and code. Bard is able to generate text, translate languages, write different kinds of creative content and answer your questions in an informative way.</p>

<p>Bard can also be used as a guidance tool for software development. Sometimes, our developers have found it useful to get some coding suggestions or best practices and infrastructure configurations for different scenarios. We also experimented with Bard for the Radar's language translations and got decent results to create the first draft of the text. Although the tool is still in development, which is why it can be a bit slower when compared to ChatGPT, we encourage developers to explore the tool and assess its potential benefits.</p>",,,,,,,,,,,,,,,,,,,,,MS Copilot,hold,Tools,TRUE,"Copilot is integrated into Microsoft 365 in two ways. It works alongside you, embedded in the Microsoft 365 apps you use every day — Word, Excel, PowerPoint, Outlook, Teams and more — to unleash creativity, unlock productivity and uplevel skills. Today we’re also announcing an entirely new experience: Business Chat. Business Chat works across the LLM, the Microsoft 365 apps, and your data — your calendar, emails, chats, documents, meetings and contacts — to do things you’ve never been able to do before. You can give it natural language prompts like “Tell my team how we updated the product strategy,” and it will generate a status update based on the morning’s meetings, emails and chat threads.

With Copilot, you’re always in control. You decide what to keep, modify or discard. Now, you can be more creative in Word, more analytical in Excel, more expressive in PowerPoint, more productive in Outlook and more collaborative in Teams.",,,,,,,,,,,,,,,,,,,,,New Relic,Trial,Tools,TRUE,"<p><strong><a href=""https://docs.newrelic.com/docs/infrastructure/microsoft-azure-integrations/get-started/azure-native/"">new relic</a></strong> New Relic is a cloud-based observability platform that provides monitoring and performance management solutions for various environments, including Azure. 

New Relic's capabilities for Azure monitoring include:

Application Performance Monitoring (APM): New Relic can monitor the performance of your applications running on Azure. It helps identify and troubleshoot issues related to application code, dependencies, and overall performance.

Infrastructure Monitoring: You can use New Relic to monitor the infrastructure components of your Azure environment. This includes tracking the performance and health of servers, virtual machines, and other infrastructure elements.

Logging and Error Tracking: New Relic allows you to collect and analyze logs from your Azure applications and infrastructure. It helps in identifying errors, exceptions, and other issues in real-time.

Synthetic Monitoring: With synthetic monitoring, New Relic enables you to simulate user interactions with your applications. This helps in proactively identifying performance issues and ensuring a positive user experience.

Dashboards and Visualization: New Relic provides customizable dashboards and visualization tools to help you gain insights into the performance and health of your Azure resources. This includes the ability to create custom charts, graphs, and reports.

Alerting and Notification: Set up alerts based on predefined or custom conditions to receive notifications when performance metrics deviate from the expected norms. This helps in proactive issue resolution.

Integration with Azure Services: New Relic can integrate with various Azure services, allowing you to monitor and analyze data from Azure storage, databases, compute instances, and other services.

Cost Monitoring: Some observability platforms, including New Relic, offer features to monitor and analyze cloud costs. This can help you optimize your Azure resources and control expenses.

Security Monitoring: Monitor and analyze security-related events in your Azure environment to identify and respond to potential security threats.

It's essential to check the latest documentation or contact New Relic directly for the most up-to-date information on their features and capabilities for Azure monitoring.",,,,,,,,,,,,,,,,,,,,,Grafana,Assess,Tools,TRUE,"<p><strong><a href=""https://grafana.com/products/cloud/?src=ggl-s&mdm=cpc&cnt=118483912276&camp=b-grafana-exac-emea&trm=grafana"">Grafana</a></strong> Grafana is a popular open-source analytics and monitoring platform that integrates with various data sources, including Azure Monitor for monitoring Azure services. Here's a summary of what Grafana can do for Azure monitoring:

Unified Dashboarding: Grafana provides a unified platform for creating interactive and customizable dashboards. You can aggregate data from Azure Monitor and other sources into a single, visually appealing dashboard.

Data Source Integration: Grafana supports Azure Monitor as a data source, allowing you to pull in metrics, logs, and other monitoring data from Azure services seamlessly.

Visualization: Grafana offers a wide range of visualization options, including charts, graphs, and tables, to help you better understand and analyze your Azure monitoring data. You can customize visualizations to suit your specific needs.

Alerting: Grafana allows you to set up alerts based on Azure Monitor metrics and logs. This feature helps you proactively respond to issues by notifying you when certain thresholds are breached.

Template Variables: You can use template variables in Grafana to create dynamic dashboards that adapt to different environments or scenarios. This is particularly useful for monitoring multiple Azure resources.

Annotations: Grafana supports annotations, which enable you to add contextual information to your dashboards. You can use annotations to highlight specific events or changes in your Azure environment.

Logging Integration: Grafana can integrate with Azure Log Analytics, allowing you to query and visualize log data alongside metrics. This provides a comprehensive view of both performance metrics and log information.

Multi-Tenancy: Grafana supports multi-tenancy, making it suitable for organizations with complex Azure environments. It allows you to create separate dashboards and configurations for different teams or projects.

Custom Plugins: Grafana has a plugin architecture that allows you to extend its functionality. There are community-developed plugins and integrations that can enhance your Azure monitoring experience.

Open Source and Community Support: Grafana's open-source nature means that it has a large and active community. This community support ensures ongoing development, regular updates, and a wealth of resources for troubleshooting and customization.

In summary, Grafana enhances Azure monitoring by providing a flexible and powerful platform for visualizing and analyzing data from Azure Monitor, allowing users to create insightful dashboards and set up effective alerting for their Azure resources.",,,,,,,,,,,,,,,,,,,,,OnePlan,Assess,Tools,TRUE,"<p><strong><a href=""https://oneplan.ai/"">OnePlan</a></strong> OnePlan offers an AI-enabled Strategic Portfolio, Financial, Resource and Work Management Platform that fits the needs of every organization. OnePlan connects with Microsoft Project, Project for the web, Microsoft Planner, Azure DevOps, Jira, Smartsheet and more for a complete view into all work across the enterprise.",,,,,,,,,,,,,,,,,,,,,Triskell,Assess,Tools,TRUE,"<p><strong><a href=""https://triskellsoftware.com/solutions/project-portfolio-management/"">Triskell</a></strong>Triskell’s PPM software streamlines project management by centralizing information and equipping users with powerful tools. With a single, intuitive platform, stakeholders can access and manage crucial project data, resulting in informed decision-making and alignment with strategic objectives.

Our software simplifies the project lifecycle by offering features for project selection, monitoring, and collaboration. You can objectively assess project proposals using customized evaluation criteria and scoring models. These criteria include strategic alignment, ROI, resource requirements, risk assessment, and more. By leveraging these evaluation models, you can confidently select projects that align with your goals and resources.

Once projects are underway, Triskell’s PPM software provides real-time dashboards and reports displaying key performance indicators. This enables stakeholders to monitor project health, identify bottlenecks, and make data-driven decisions. It also facilitates resource allocation and capacity planning, ensuring optimal resource utilization. Our collaboration features promote seamless communication, document sharing, and task management among project teams, enhancing transparency and team productivity for successful project execution.",,,,,,,,,,,,,,,,,,,,,Planview,Assess,Tools,TRUE,"<p><strong><a href=""https://www.planview.com/products-solutions/solutions/project-portfolio-management/"">Planview</a></strong>Leading organizations are building agility for change by
embracing strategic portfolio management to transform
operations and drive business value. This is the key to staying
competitive in an ever-changing environment where strategic trade-offs and reallocation of funding
and resources are needed to deliver business priorities at speed.
With Planview’s strategic portfolio management solution, executives, finance, and EPMOs can drive
their organizations’ transformation and initiatives, adapt with change, and accelerate on-strategy
delivery.",,,,,,,,,,,,,,,,,,,,,
